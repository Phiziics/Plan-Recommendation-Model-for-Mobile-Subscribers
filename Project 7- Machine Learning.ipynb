{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The aim of this project is to develop a machine learning model that can accurately classify subscribers based on their mobile phone usage data and recommend one of Megaline's newer plans, Smart or Ultra. The goal is to analyze the behavior patterns of Megaline's subscribers and identify which plan (Smart or Ultra) best suits their needs.\n",
    "\n",
    "By achieving this, Megaline can offer personalized plan recommendations to its subscribers, leading to an improved customer experience and potential increases in customer satisfaction and retention. The classification model will be evaluated for its performance on a test dataset, with the objective of reaching a minimum accuracy of 0.75.\n",
    "\n",
    "In summary, the project aims to:\n",
    "\n",
    "Develop a classification model that can accurately predict whether a subscriber should switch to the Smart or Ultra plan based on their mobile usage data.\n",
    "Analyze and understand the behavior patterns of Megaline's subscribers.\n",
    "Enhance customer satisfaction and retention through personalized plan recommendations that align with each subscriber's unique usage profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv file into a data frame\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>122.0</td>\n",
       "      <td>910.98</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35124.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>25.0</td>\n",
       "      <td>190.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3275.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>97.0</td>\n",
       "      <td>634.44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13974.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>64.0</td>\n",
       "      <td>462.32</td>\n",
       "      <td>90.0</td>\n",
       "      <td>31239.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>80.0</td>\n",
       "      <td>566.09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29480.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "0      40.0   311.90      83.0  19915.42         0\n",
       "1      85.0   516.75      56.0  22696.96         0\n",
       "2      77.0   467.66      86.0  21060.45         0\n",
       "3     106.0   745.53      81.0   8437.39         1\n",
       "4      66.0   418.74       1.0  14502.75         0\n",
       "...     ...      ...       ...       ...       ...\n",
       "3209  122.0   910.98      20.0  35124.90         1\n",
       "3210   25.0   190.36       0.0   3275.61         0\n",
       "3211   97.0   634.44      70.0  13974.06         0\n",
       "3212   64.0   462.32      90.0  31239.78         0\n",
       "3213   80.0   566.09       6.0  29480.52         1\n",
       "\n",
       "[3214 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the dataframe which displays the head and the tail, which is the first 5 rows and last 5 rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicated rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values/ null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "#checking the data types using the info method\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the messages datatype\n",
    "df['messages'] = df['messages'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   int64  \n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "#checking to see changes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train dataframe: (1928, 5)\n",
      "Shape of valid dataframe: (643, 5)\n",
      "Shape of Test dataframe: (643, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split data frame into train, valid, and test dataframes in a 3:1:1 ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=77)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=77)\n",
    "\n",
    "print(f\"Shape of the train dataframe: {train_df.shape}\")\n",
    "print(f\"Shape of valid dataframe: {valid_df.shape}\")\n",
    "print(f\"Shape of Test dataframe: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature and target for each dataframes also known as X and y\n",
    "train_features, train_target = train_df.drop(['is_ultra'], axis=1), train_df['is_ultra']\n",
    "valid_features, valid_target = valid_df.drop(['is_ultra'], axis=1), valid_df['is_ultra']\n",
    "test_features, test_target = test_df.drop(['is_ultra'], axis=1), test_df['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: DecisionTreeClassifier(max_depth=7, random_state=77)\n",
      "Accuracy of the best model: 0.7916018662519441\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = 0\n",
    "for depth in range(1, 8):\n",
    "    # create a model with the given depth\n",
    "    tree_model = DecisionTreeClassifier(random_state=77, max_depth=depth)\n",
    "    # train the model\n",
    "    tree_model.fit(train_features, train_target)\n",
    "    # get the model's predictions\n",
    "    tree_predictions = tree_model.predict(valid_features)\n",
    "    # calculate the accuracy\n",
    "    result = accuracy_score(valid_target, tree_predictions) \n",
    "    if result > best_result:\n",
    "        best_model = tree_model\n",
    "        best_result = result\n",
    "\n",
    "print(\"Best model:\", tree_model)\n",
    "print(\"Accuracy of the best model:\", best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best random forest model on the validation set (n_estimators = 14): 0.7931570762052877\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "# choose hyperparameter range\n",
    "for est in range(1,18):\n",
    "    # set number of trees\n",
    "    forest_model = RandomForestClassifier(random_state=77, n_estimators=est)\n",
    "    # train model on training set\n",
    "    forest_model.fit(train_features, train_target)\n",
    "    # calculate accuracy score on validation set\n",
    "    score = forest_model.score(valid_features, valid_target)\n",
    "    if score > best_score:\n",
    "        # save best accuracy score on validation set\n",
    "        best_score = score\n",
    "        # save number of estimators corresponding to best accuracy score\n",
    "        best_est = est\n",
    "\n",
    "print(f\"Accuracy of the best random forest model on the validation set (n_estimators = {best_est}): {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the validation set: 0.7060653188180405\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regresiion training and testing\n",
    "lr_model = LogisticRegression(random_state=77, solver='liblinear')  # initialize logistic regression constructor with parameters random_state=54321 and solver='liblinear'\n",
    "#Train model on training set\n",
    "lr_model.fit(train_features, train_target)\n",
    "\n",
    "#calculate accuracy score on training set\n",
    "score_valid = lr_model.score(valid_features, valid_target)\n",
    "\n",
    "print(\"Accuracy of the logistic regression model on the validation set:\", score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above ML training we see that the best performing algorithm is the Random Forest. Hence we will use that as the final model and test it against the test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the algorithm on the test dataframe is: 0.8087091757387247\n"
     ]
    }
   ],
   "source": [
    "# Testing the random forest algothim agaisnt the test dataframe\n",
    "# change n_estimators to get best model\n",
    "final_model = RandomForestClassifier(random_state=77, n_estimators=14)\n",
    "final_model.fit(train_features, train_target)\n",
    "\n",
    "# get the model's predictions\n",
    "final_predictions = final_model.predict(test_features)\n",
    "# calculate the accuracy\n",
    "result = accuracy_score(test_target, final_predictions)\n",
    "\n",
    "print(f\"Accuracy score of the algorithm on the test dataframe is: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19129082426127528"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean squared error\n",
    "mse = mean_squared_error(test_target, final_predictions)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE is approximately 0.1913.\n",
    "A lower MSE value indicates that the model's predictions are closer to the actual values, suggesting better model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[406  41]\n",
      " [ 82 114]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Calculate and display confusion matrix\n",
    "conf_matrix = confusion_matrix(test_target, final_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=np.unique(test_target), yticklabels=np.unique(test_target))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, there were 406 true positives/ correct positive prediction and 41 false positives/ 41 incorrect positive predictions, while there was 114 true negatives/ correct negative predictions and 82 false negatives/ incorrect negative predictions.\n",
    "\n",
    "From the matix we can calculate:\n",
    "- Precision- TP/(TP+FP) where TP is true positives (correctly predicted positives), and FP is false positives (incorrectly predicted positives). Precision indicates how many of the model's positive predictions were actually correct. High precision means that the model is making very few false positive predictions.\n",
    "114/(114+41) = 114/155 = 0.735\n",
    "\n",
    "- Recall- TP/(TP+FN) where TP is true positives (correctly predicted positives), and FN is false negatives (actual positives not predicted).\n",
    "114/(114+82) = 114/196 = 0.581\n",
    "\n",
    "- F1-Score- 2*(Precision*Recall)/ (Precision+Recall) he F1-score is a comprehensive metric that combines both precision and recall into a single score. It is useful when you want to find a balance between precision and recall, especially if one metric is disproportionately higher than the other.\n",
    "2*(0.74*0.58)/(0.74+0.58) = 2*(0.43)/1.32 = 0.86/1.32 = 0.65\n",
    "\n",
    "We can further calculate more data with the classification report below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       447\n",
      "           1       0.74      0.58      0.65       196\n",
      "\n",
      "    accuracy                           0.81       643\n",
      "   macro avg       0.78      0.74      0.76       643\n",
      "weighted avg       0.80      0.81      0.80       643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display precision, recall, and F1 score\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_target, final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report summarizes the model's performance across different classes:\n",
    "\n",
    "- Precision measures the proportion of correct positive predictions out of all predicted positives. High precision implies accurate positive class predictions. Class 0 has a precision of 0.83, showing strong accuracy for the negative class. Class 1's precision is 0.74, indicating somewhat accurate positive class predictions.\n",
    "\n",
    "- Recall measures the proportion of correct positive predictions out of all actual positive cases. High recall indicates successful identification of most actual positive cases. Class 0's recall of 0.91 demonstrates excellent identification of negative cases. Class 1's recall is 0.58, indicating missed positive cases.\n",
    "\n",
    "- F1-Score is the harmonic mean of precision and recall, balancing the trade-off between them. Class 0 has an F1-score of 0.87, indicating a strong balance for the negative class. Class 1's F1-score of 0.65 suggests room for improvement in balancing precision and recall.\n",
    "\n",
    "- Support is the count of each class in the dataset, with 447 instances of class 0 and 196 instances of class 1.\n",
    "\n",
    "Overall accuracy of 0.81 means the model correctly classified 81% of observations.\n",
    "Macro and weighted averages calculate the average precision, recall, and F1-score across classes, with macro average giving equal weight to each class, and weighted average adjusting for class support.\n",
    "In summary, the model excels at classifying the negative class (class 0), but improvement is needed for identifying the positive class (class 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "#### Machine Learning Models\n",
    "In this project, we aimed to develop a model that can accurately classify Megaline's subscribers based on their mobile phone usage data and recommend one of the company's newer plans, Smart or Ultra. We explored three different machine learning models: decision tree, random forest, and logistic regression, and evaluated their performance on test and validation datasets.\n",
    "\n",
    "- The decision tree model (DecisionTreeClassifier with a maximum depth of 7 and a random state of 77) achieved an accuracy of 0.7916 on the test set. This model offers interpretability and simplicity, making it a solid choice for classification tasks.\n",
    "\n",
    "- The random forest model (RandomForestClassifier with 14 estimators) performed the best, achieving an accuracy of 0.7932 on the validation set. This model demonstrates strong predictive accuracy and robustness due to its ensemble approach, making it the top performer in this study.\n",
    "\n",
    "- The logistic regression model achieved an accuracy of 0.7061 on the validation set. While logistic regression is a straightforward classification algorithm, its performance in this specific task was not as strong compared to the other models.\n",
    "\n",
    "- Based on the results, the random forest model stands out as the most suitable choice for this task due to its slightly higher accuracy and robust performance. However, the decision tree model remains a strong alternative, providing a more interpretable model.\n",
    "\n",
    "- Future work could involve fine-tuning the chosen models, exploring other types of algorithms, or incorporating additional data features to further improve classification accuracy. Additionally, monitoring model performance over time can ensure that the model remains effective as subscriber behavior patterns evolve.\n",
    "\n",
    "#### Confusion Matrix\n",
    "- The classification report shows that the model performs well in classifying the negative class (class 0) with high precision (0.83) and recall (0.91), leading to an F1-score of 0.87. However, the model struggles more with classifying the positive class (class 1), with lower precision (0.74) and recall (0.58), resulting in an F1-score of 0.65. The overall accuracy of 0.81 is good, but there is room for improvement in identifying positive cases more accurately to achieve a better balance between precision and recall across both classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
